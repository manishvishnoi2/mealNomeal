{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger('tsfresh').setLevel(logging.ERROR)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tsfresh import extract_features, select_features,feature_selection\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.metrics import roc_auc_score as AUC, accuracy_score as accuracy\n",
    "from sklearn.svm import SVC as SVM\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.linear_model import SGDClassifier as SGD\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier as GPC\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    result = pd.DataFrame()\n",
    "#     Extracting Data for meal class\n",
    "\n",
    "    for x in range(5):\n",
    "        d = pd.read_csv('data/mealData'+str(x+1)+'.csv', header = None,error_bad_lines=False)\n",
    "        d['y']= 1\n",
    "        result = pd.concat([result,d])\n",
    "    \n",
    "#     Extracting data for no meal class\n",
    "    for x in range(5):\n",
    "        d = pd.read_csv('data/Nomeal'+str(x+1)+'.csv', header = None,error_bad_lines=False)\n",
    "        d['y']= 0\n",
    "        result = pd.concat([result,d])\n",
    "        \n",
    "#         Imputing for NaN value removal\n",
    "    result = impute_data(result)\n",
    "    \n",
    "#     Renaming Target column to dataframe\n",
    "    result = pd.DataFrame(result)\n",
    "    columns = list(result.columns)\n",
    "    columns.pop()\n",
    "    columns.append('target')\n",
    "    result.columns = columns\n",
    "    \n",
    "#     Extracting features and writing into files\n",
    "    features = feature_extract(result,'data/features_file.csv')\n",
    "#     Cross fold validation and Training models\n",
    "    classifier()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(result, filename):\n",
    "    y = result.target\n",
    "    result.drop( 'target', axis = 1, inplace = True )\n",
    "    d = result.stack()\n",
    "    d.index.rename([ 'id', 'time' ], inplace = True )\n",
    "    d = d.reset_index()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        f = extract_features( d, column_id = \"id\", column_sort = \"time\")\n",
    "    impute(f)\n",
    "    assert f.isnull().sum().sum() == 0\n",
    "    result_ml = feature_selection.relevance.calculate_relevance_table(f, y, ml_task='auto', n_jobs=2, chunksize=None, test_for_binary_target_binary_feature='fisher', test_for_binary_target_real_feature='mann', test_for_real_target_binary_feature='mann', test_for_real_target_real_feature='kendall', fdr_level=0.05, hypotheses_independent=False)\n",
    "    result_ml = result_ml[result_ml['relevant']==True]\n",
    "    f=f[result_ml['feature']]\n",
    "    f['y'] = y\n",
    "    f.to_csv( filename, index = None )\n",
    "    columns = f.columns\n",
    "    columns = pd.DataFrame(columns)\n",
    "    columns.to_csv(\"data/features_name.csv\", index=None)\n",
    "    return f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(result):\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "    imp_mean.fit(result)\n",
    "    return(imp_mean.transform(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier():\n",
    "    data = pd.read_csv(\"data/features_file.csv\")\n",
    "    classifiers, classifiers_name = classi_vals()\n",
    "    idx = 0\n",
    "    scoring= ['accuracy','precision_macro', 'recall_macro','f1_macro']\n",
    "    for clf in classifiers: \n",
    "        print(\"Classifer : {}\".format(classifiers_name[idx]))\n",
    "        idx+=1\n",
    "        scores = cross_validate(clf,data.loc[:, data.columns != 'y'],data['y'],cv = 5,scoring = scoring)\n",
    "        print(\"Average score are {}, Average Precision is {},Average Recall is {}, Average f1 score is {}\".format(np.mean(scores['test_accuracy']),np.mean(scores['test_precision_macro']),np.mean(scores['test_recall_macro']),np.mean(scores['test_f1_macro'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classi_vals():\n",
    "    classifiers = [   \n",
    "        make_pipeline( StandardScaler(), LR()),\n",
    "        make_pipeline( MinMaxScaler(), LR()),\n",
    "        make_pipeline( MinMaxScaler(), SVM(gamma='auto', probability=True)),\n",
    "        RF( n_estimators = 100, min_samples_leaf = 5 ),\n",
    "        SGD(random_state = 42),\n",
    "        GPC(1.0 * RBF(1.0)),\n",
    "        ABC(),\n",
    "        NB(),\n",
    "        DTC(max_depth = 5)\n",
    "    ]\n",
    "    classifiers_names = [\"Logistic Regression(Standard Scalar)\",\"Logistic Regression(MinMax Scalar)\",\"SVM\",\"RandomForest\",\"Stocahastic gradient descent\",\"Gaussian Process Classifier\",\"Ada boost\",\"Naive bayes\",\"Decision Trees\"]\n",
    "    return classifiers, classifiers_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 29/29 [00:06<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifer : Logistic Regression(Standard Scalar)\n",
      "Average score are 0.6006311803071743, Average Precision is 0.6017359785430016,Average Recall is 0.6001411564625851, Average f1 score is 0.5970754282575271\n",
      "Classifer : Logistic Regression(MinMax Scalar)\n",
      "Average score are 0.6193141173995371, Average Precision is 0.6216131393300928,Average Recall is 0.6190561224489796, Average f1 score is 0.6154333019854679\n",
      "Classifer : SVM\n",
      "Average score are 0.6439511887229118, Average Precision is 0.6471401242213606,Average Recall is 0.6430425170068028, Average f1 score is 0.6336955952648907\n",
      "Classifer : RandomForest\n",
      "Average score are 0.615148327372186, Average Precision is 0.6180659273258893,Average Recall is 0.6148452380952381, Average f1 score is 0.6094266128944321\n",
      "Classifer : Stocahastic gradient descent\n",
      "Average score are 0.5185356616873553, Average Precision is 0.31708281437191943,Average Recall is 0.5153486394557824, Average f1 score is 0.38316026916409396\n",
      "Classifer : Gaussian Process Classifier\n",
      "Average score are 0.5041026719966337, Average Precision is 0.25256679991584263,Average Recall is 0.4979591836734694, Average f1 score is 0.33514432713299036\n",
      "Classifer : Ada boost\n",
      "Average score are 0.5968230591205554, Average Precision is 0.6002733429336405,Average Recall is 0.5965578231292518, Average f1 score is 0.5938765003923141\n",
      "Classifer : Naive bayes\n",
      "Average score are 0.6255838417841363, Average Precision is 0.6479556420684399,Average Recall is 0.6274914965986393, Average f1 score is 0.6121485675232716\n",
      "Classifer : Decision Trees\n",
      "Average score are 0.596717862402693, Average Precision is 0.5984099372912757,Average Recall is 0.5966921768707483, Average f1 score is 0.595731657778423\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
